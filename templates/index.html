<!DOCTYPE html>
<html>
<!-- CSS For this Kust an attempt -->
<style>
    .button{
        border: none;
        color: white;
        padding: 5px 15px;
        text-align: center;
        text-decoration: none;
        display: inline-block;
        font-size: 16px;
        margin: 4px 2px;
        cursor: pointer;
    }
    .red{background-color: #f44336;}
    .green{background-color: green;}
    #canvas-container{
        width: 100%;
        text-align: center;
    }
    canvas{
        display: inline;
    }
    h1{
        font-size: 50px;
        line-height: 1;
    }
</style>
<!-- Thank god CSS ended -->

<!-- JQuery for the ajax call and http request-->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

<!-- Main Javascript code for making the canvas and mouse handling -->
<script type="text/javascript">
    var canvas, ctx, flag = false,
    prevX = 0,
    currX = 0,
    prevY = 0,
    currY = 0;

    function init() {
        canvas = document.getElementById('can');
        ctx = canvas.getContext("2d");
        ctx.fillStyle = "black";
        ctx.fillRect(0, 0, canvas.width, canvas.height);
        ctx.strokeStyle = "white";
        ctx.lineWidth = 5;
        ctx.lineCap = "round";
        w = canvas.width;
        h = canvas.height;
        
        canvas.addEventListener("mousemove", function(e)
        {
            mouseEventHandler("move", e)
        }, false);

        canvas.addEventListener("mousedown", function(e){
            mouseEventHandler("down", e);
        }, false);

        canvas.addEventListener("mouseup", function (e) {
            mouseEventHandler('up', e)
        }, false);
        canvas.addEventListener("mouseout", function (e) {
            mouseEventHandler('out', e)
        }, false);    
    }

    function draw(){
        ctx.beginPath();
        ctx.moveTo(prevX, prevY);
        ctx.lineTo(currX, currY);
        ctx.stroke();
        ctx.closePath();
    }

    function erase(){
        ctx.fillStyle = "black";
        ctx.fillRect(0, 0, w, h);
    }
// Upload the digit from the canvas
    function upload(){

        // Convert to jpeg image
        var dataURL = canvas.toDataURL("image/jpeg", 0.8);
        // Ajax call to the server
        $.ajax({
            type:"POST",
            url:"/upload",
            data:{"data":dataURL},
            success: function(data){
                console.log(data)
                var json = JSON.parse(data)
                $("#output").html("<string> Recognized Digit </strong> :" + json.class + "<br> <strong> Confidence </strong>" + json.confidence)

            },
            error: function (data) 
            {
                console.log("Upload failed")
            }
        }).done(function(){console.log("Sent");});
    }
    function mouseEventHandler(res, e) 
    {
        if (res == 'down') {
            prevX = currX;
            prevY = currY;
            currX = e.clientX - canvas.offsetLeft;
            currY = e.clientY - canvas.offsetTop;
    
            flag = true;
        }
        if (res == 'up' || res == "out") {
            flag = false;
        }
        if (res == 'move') {
            if (flag) {
                prevX = currX;
                prevY = currY;
                currX = e.clientX - canvas.offsetLeft;
                currY = e.clientY - canvas.offsetTop;
                draw();
            }
        }
    }

</script>


<!-- HTML Layout of the app -->
<body onload="init()">
    <div style="text-align: center; padding: 10px;">
      <a href="https://www.bharathkreddy.com"><img align="center" src="https://i.imgur.com/axjt3Qe.png" alt="WWW.BHARARTHKREDDY.COM" title="www.bharathkreddy.com"></a>
      <a href="https://www.bharathkreddy.com">www.bharathkreddy.com</a> 
    </div>
    <div id = "canvas-container">
        <h1>Digit Recognizer</h1>
        <div style="text-align: center; padding: 10px;">
            <input type="button" value="Clear" id="clr" size="30" onclick="erase()" class="red button">
            <input type="button" value="Upload" id="clr" size="30" onclick="upload()" class="green button">
        </div>
        <canvas id="can" width="256" height="256" > </canvas>
        <p id="output">Scribble a digit and upload to run the algorithm.</p>
    </div>
    <div>
        <h2>About the app</h2>
        <p>This app can recognize handwritten digits. Draw a digit on the canvas above and press the "Recognize"
                button to see a prediction. Press the "Clear" button to clear the canvas and draw a digit again. The app
                also gives a confidence score to its prediction.</p>
    </div>
    <div class="container">	 
			<div class="col-md-4"><h2>1. Motivation</h2>
				After completing cs231n course (with a study group) I wanted to do something like a final project, but with interactivity, so that anyone could use it. Also I hoped to acquire or hone some practical skills on the way. So it was decided to try a simple project with a number of conditions. It would be digit recognition (a classi—Å problem), but training data should be collected by myself (using MNIST or CIFAR or some other data set wouldn't be as interesting) and this should work online and be interactive - this means building a site. Additionally I thought that it would be cool, if model's performance could change and improve based on the input.
			</div>
			<div class="col-md-4"><h2>2. First plans</h2>
				The initial step of doing a project is outlining a plan. First of all it was necessary to collect the data. The best way to do it is to create a draft version of the site with minimal functionality and possibility to draw and save digit. But how many images are necessary? Neural nets usually require a lot of data. A solution lies in data augmentation technics which can increase the volume data manifold. Then a model should be trained on the data and be able to be trained on additional data. This model should be able to generate predictions and show them on site. This is a general outline.
			</div>
			<div class="col-md-4"><h2>Basic site</h2>
				<img src = "/static/1.jpg" alt = "Basic site screenshot" height="260" style="border: 1px solid #000000"> </img>
			</div>
			<div class="col-md-4"><h2>3. Basic site</h2>
				There are several popular frameworks for Web development in Python, among them I was familiar only with Flask and decided to try it. It turned out to be quite easy to set up a basic site. Making a canvas for drawing turned out to be more challenging. In the end I have found a code on Github which was simple enough and it worked after some modifications. So the site had only canvas, radio buttons for selecting the digit and buttons to save the digit and to clear the canvas. Now the question was: where should the digits be saved. A good idea would be to save them online, but Heroku doesn't allow saving new files (only temporarily) and I decided to upload images to Amazon.
			</div>
			<div class="col-md-4"><h2>4. Collecting data</h2>
				It turned out that there are good packages for Amazon, which make things quite simple (namely boto). I was able to upload and download files from the bucket, though it took more time to integrate this into the site so that drawn images would be uploaded to the cloud. It took me several days to draw 1000 images. Then I studied images on MNIST dataset and decided to do the following augmentations: resize the image so that its width and height are increased/decreased and turning the image by certain angles. This results in 24 images for each original image.
			</div>
			<div class="col-md-4"><h2>FNN training progress</h2>
				<img src = "/static/2.jpg" alt = "FNN training progress" height="260" style="border: 1px solid #000000"> </img>
			</div>
			<div class="col-md-4"><h2>5. Feed forward net</h2>
				I dediced to try simple feed forward neural net at first (as opposed to CNN). After trials and errors I decided that two-layered net would be enough. Hidden layer with 100 neurons and ReLu activation, output layer with sigmoid activation. The next step after creating the net itself was preparing it for online training, so that weights could be updated for the new images. I used the same structure, but removed learning rate decay. You can read more about the model on the relevant <a href="{{ url_for('models') }}">page</a>. The accuracy was 58.95%, which isn't as high as for models trined on MNIST, but it is a beginning.
			</div>
			<div class="col-md-4"><h2>6. Bootstrap on site</h2>
				At last it was the time to make the site more presentable. The easiest way to do it was to use bootstrap. I chose a nice template and build the site using it. The most challenging part of it was to make the site look not too bad on mobile. Another tough spot was enabling drawing on canvas. It turns out that drawing with mouse and with touches are quite different things (who could have thought). I planned to have several pages with project's description, but decided to do it at the very end of the project. Also it took some time to implement and to test onclick events for buttons. 
			</div>
			<div class="col-md-4"><h2>CNN confusion matrix</h2>
				<img src = "/static/3.jpg" alt = "CNN confusion matrix" height="230" style="border: 1px solid #000000"> </img>
			</div>
			<div class="col-md-4"><h2>7. CNN</h2>
				Building FNN with only numpy is fun and everything, but better image recognition requires CNN. And writing CNN in numpy isn't fun at all. Tensorflow is currently one of the most popular Python frameworks for deep learning and I used it in this project. It took me a lot of tries and experimentations to create a good architecture. You can read more about the model on the relevant <a href="{{ url_for('models') }}">page</a>. Additional problems appeared due to the fact that the model is saved not in one file, but in three; all of them should be saved and loaded together. The accuracy was 74.69%, which is much better than FNN, but still not high.
			</div>
			<div class="col-md-4"><h2>8. Showing predictions</h2>
				One of the last question was how to show the predictions. I had several ideas, for example showing distinct top predictions from each model, but dediced against it. Currently only predictions from both trained models are taken into account. If they are the same, then their prediction is shows, if they differ, then the prediction with the highest probability is shown. And if both models predict with probability less than 50%, then a special message is shown. The table provides more detailed information. Also I wanted to calculate the quality of prediction on MNIST after each training, but free plan on Heroku can't work with this amount of data.
			</div>
			<div class="col-md-4"><h2>9. Last steps</h2>
				At this stage most of the project was completed, only several more actions were necessary. The readability of the code had to be improved, site display on different devices needed to be checked. Of course, it was also necessary to test whether the predicting power of models was improving after training. And project description should be written.
			</div>
          <footer>
            <div class="row">
                <div class="col-lg-12">
                    <p>Copyright &copy; <a href="https://www.bharathkreddy.com">Bharath k. Reddy</a></p>
                </div>
            </div>
        </footer>

    </div>
</body>
</html>
